{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aditya-singh32/My_projects/blob/main/Assignment_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Let's import the dataset by the help of sklearn library."
      ],
      "metadata": {
        "id": "UK-WZWURAdON"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn import datasets\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = datasets.load_iris()\n",
        "iris_data = iris.data\n",
        "iris_target = iris.target"
      ],
      "metadata": {
        "id": "JOmTIaBv-SNv"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Below we have split the datasets into two halves. One half is for training dataset and it contains the rows with index 0.2.4.... from the iris dataset. While the test dataset contains the rows with index 1.3.5.... from the iris dataset. Moreover, we are not including the 3rd feature from the iris dataset into any of our dataset. The concept that helped us to achieve the task is called slicing.\n",
        "\n",
        "Since, the iris dataset have 150 rows.\n",
        "Therefore, train dataset and test dataset have 75 rows each."
      ],
      "metadata": {
        "id": "An6pZIGbAqIt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = iris_data[::2,[0, 1, 3]]\n",
        "X_test = iris_data[1::2,[0,1,3]]"
      ],
      "metadata": {
        "id": "X4o1PFGb6Dc6"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = iris.target_names[iris_target[::2]]\n",
        "y_test = iris.target_names[iris_target[1::2]]\n"
      ],
      "metadata": {
        "id": "PasHb5s-95Lh"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "iris_data[:5]"
      ],
      "metadata": {
        "id": "oW_UPB3-Ee__",
        "outputId": "2902b71b-366a-4e2a-94ba-6b947621f5fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[5.1, 3.5, 1.4, 0.2],\n",
              "       [4.9, 3. , 1.4, 0.2],\n",
              "       [4.7, 3.2, 1.3, 0.2],\n",
              "       [4.6, 3.1, 1.5, 0.2],\n",
              "       [5. , 3.6, 1.4, 0.2]])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.shape,\n",
        "y_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "vDiCSni_FiPI",
        "outputId": "12f3a4ad-9649-49b0-b7d3-e763b0c63ac5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(75, 3) (75,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's concatenate our X_train along with y_train so that we could use it for X->y mapping (supervised learning). In machine learning our model learns the pattern between X and y during the training stage. This helps it later on to make predictions on new datasets."
      ],
      "metadata": {
        "id": "PtMrIlekBxLG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> We are also saving these final training and testing datasets as csv files so that we could use them on weka."
      ],
      "metadata": {
        "id": "y1XpqvfhCQ_m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_matrix = np.concatenate((X_train, y_train.reshape(-1,1)), axis = 1)\n",
        "train_matrix = np.concatenate((np.array(['sepal length (cm)', 'sepal width (cm)','petal width (cm)','class']).reshape(1,-1), train_matrix), axis = 0)\n",
        "np.savetxt('train_data_and_labels.csv', train_matrix, delimiter = ',', fmt=\"%s\")\n"
      ],
      "metadata": {
        "id": "yRvYVJqiFs5u"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_matrix = np.concatenate((X_test, y_test.reshape(-1,1)), axis = 1)\n",
        "test_matrix = np.concatenate((np.array(['sepal length (cm)', 'sepal width (cm)','petal width (cm)','class']).reshape(1,-1), test_matrix), axis = 0)\n",
        "np.savetxt('test_data_and_labels.csv', test_matrix, delimiter = ',', fmt=\"%s\")\n"
      ],
      "metadata": {
        "id": "9t9q6AVIF-pc"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## KNN model from SK-Learn Library"
      ],
      "metadata": {
        "id": "jku05XBmD25G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The results from this model should be same as the Weka results as it does the same thing that Weka does."
      ],
      "metadata": {
        "id": "klIA-HlDCbxK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "# I made sure to have n_neighbors as 1 and metric as euclidean so that my solutions matches with the weka solution.\n",
        "model = KNeighborsClassifier(n_neighbors=1, metric='euclidean')\n",
        "\n",
        "model.fit(X_train,y_train)"
      ],
      "metadata": {
        "id": "JEOl8V-H-WCv",
        "outputId": "e3835a8a-f358-4e14-f195-ae5b71ea2754",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KNeighborsClassifier(metric='euclidean', n_neighbors=1)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier(metric=&#x27;euclidean&#x27;, n_neighbors=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier(metric=&#x27;euclidean&#x27;, n_neighbors=1)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This tells us the accuracy of this model which is same as the weka and our knn function.\n",
        "model.score(X_test,y_test)"
      ],
      "metadata": {
        "id": "iYjFHVDr7e6A",
        "outputId": "cf0815bd-0763-4785-8bbb-6a316ca57325",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9333333333333333"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Compare predictions with ground truth\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Model Accuracy: {accuracy}\")\n",
        "\n",
        "# Identify rows where predictions are incorrect\n",
        "incorrect_rows = X_test[y_test != y_pred]"
      ],
      "metadata": {
        "id": "lAT8xNXc7stf",
        "outputId": "dbb53cce-718d-46a3-ac6b-70861258d504",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy: 0.9333333333333333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Same as Weka's and our function\n",
        "incorrect_rows"
      ],
      "metadata": {
        "id": "d__c5NHs8L4_",
        "outputId": "9e6b7035-210e-4372-cc90-0e03e80e5a87",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[6.1, 2.8, 1.3],\n",
              "       [6.1, 2.8, 1.2],\n",
              "       [6. , 2.2, 1.5],\n",
              "       [7.2, 3. , 1.6],\n",
              "       [6.3, 2.8, 1.5]])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's find the exact index of the rows that were predicted incorrectly. The answer is same as the Weka's answer and our KNN function."
      ],
      "metadata": {
        "id": "0aOp-IiuJHd8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.where(y_test != y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "Jfm3K9IAVOrK",
        "outputId": "278f0240-6143-43c4-f201-72cb15e4f159"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([35, 36, 59, 64, 66]),)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Our KNN function and its accuracy"
      ],
      "metadata": {
        "id": "HHcuAnnyDyv_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to calculate the distance between each row of two datasets\n",
        "def calculate_distances(train_data, test_data):\n",
        "    distances = np.zeros((test_data.shape[0], train_data.shape[0]))\n",
        "\n",
        "    for i, test_row in enumerate(test_data):\n",
        "        for j, train_row in enumerate(train_data):\n",
        "            # Euclidean distance\n",
        "#            distances[i, j] = np.linalg.norm(test_row - train_row)\n",
        "            distances[i, j] = np.sqrt(np.sum((test_row - train_row)**2))\n",
        "\n",
        "    return distances"
      ],
      "metadata": {
        "id": "pOri_IxSDCal"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Two ways to calculate the nearest neighbors of our test dataset."
      ],
      "metadata": {
        "id": "FzsvuA5PJYvn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "distances = calculate_distances(X_train, X_test)\n",
        "\n",
        "for i in range(len(X_train)):\n",
        "    # Calculate distances from the i-th sample to all samples in the training set\n",
        "    distances[i][i] = np.inf\n",
        "    nearest_neighbors_indices[i] = np.argmin(distances[i])\n",
        "\n",
        "nearest_neighbors_indices"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "jNzu4m4kx9V9",
        "outputId": "ba405a3a-1aee-4497-a23d-207419460ca1"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([17, 15,  8,  0, 17, 12, 19,  8, 20, 23, 22, 13, 17, 14,  1, 10,  7,\n",
              "       15,  2,  0,  4, 13, 15,  1, 17, 28, 40, 48, 49, 45, 39, 39, 43, 41,\n",
              "       40, 67, 67, 29, 43, 46, 45, 39, 35, 34, 45, 39, 49, 48, 37, 48, 71,\n",
              "       63, 61, 65, 60, 64, 71, 52, 60, 34, 71, 63, 51, 69, 26, 61, 27, 61,\n",
              "       58, 56, 60, 60, 70, 58, 69])"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_samples = len(X_train)\n",
        "\n",
        "nearest_neighbors_indices = np.zeros(n_samples, dtype=int)\n",
        "\n",
        "for i in range(n_samples):\n",
        "    # Calculate distances from the i-th sample to all samples in the training set\n",
        "    distances = calculate_distances(X_train, X_test[i].reshape(1, -1)).flatten()\n",
        "    distances[i] = np.inf\n",
        "\n",
        "    nearest_neighbors_indices[i] = np.argmin(distances)\n",
        "\n",
        "nearest_neighbors_indices"
      ],
      "metadata": {
        "id": "mYHreQwTpuMN",
        "outputId": "e0c2898b-65b7-408e-8823-c6160483a5ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([17, 15,  8,  0, 17, 12, 19,  8, 20, 23, 22, 13, 17, 14,  1, 10,  7,\n",
              "       15,  2,  0,  4, 13, 15,  1, 17, 28, 40, 48, 49, 45, 39, 39, 43, 41,\n",
              "       40, 67, 67, 29, 43, 46, 45, 39, 35, 34, 45, 39, 49, 48, 37, 48, 71,\n",
              "       63, 61, 65, 60, 64, 71, 52, 60, 34, 71, 63, 51, 69, 26, 61, 27, 61,\n",
              "       58, 56, 60, 60, 70, 58, 69])"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds = y_train[nearest_neighbors_indices]"
      ],
      "metadata": {
        "id": "Kx1VEfgUpwg4"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "incorrect_rows = X_test[y_test != preds]"
      ],
      "metadata": {
        "id": "iubMLC5NC_ob"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "incorrect_rows"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "JWF_DCO4DAwx",
        "outputId": "f44aae18-274f-4afc-882a-c0ab2a4bb1ec"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[6.1, 2.8, 1.3],\n",
              "       [6.1, 2.8, 1.2],\n",
              "       [6. , 2.2, 1.5],\n",
              "       [7.2, 3. , 1.6],\n",
              "       [6.3, 2.8, 1.5]])"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Accuracy of our model"
      ],
      "metadata": {
        "id": "HPo1Yg4lgitM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(y_test == preds).mean()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "AQfY5c-bgafH",
        "outputId": "f7691fdd-f25c-4afb-99f8-9bbea1a7848e"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9333333333333333"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Index of the incorrectly predicted rows. This is same as the KNN model of Weka and Sklearn."
      ],
      "metadata": {
        "id": "gY6pOulYVGD2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.where(y_test != preds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "-FT9gqfcVAaa",
        "outputId": "0cea462e-7893-4fe2-a51c-b38f083e447f"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([35, 36, 59, 64, 66]),)"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Result of Weka (Same as the KNN modle of sklearn library and our KNN function)\n",
        "\n",
        "=== Run information ===\n",
        "\n",
        "Scheme:       weka.classifiers.lazy.IBk -K 1 -W 0 -A \"weka.core.neighboursearch.LinearNNSearch -A \\\"weka.core.EuclideanDistance -D -R first-last\\\"\"\n",
        "Relation:     train_data_and_labels (2)\n",
        "Instances:    75\n",
        "Attributes:   4\n",
        "              sepal length (cm)\n",
        "              sepal width (cm)\n",
        "              petal width (cm)\n",
        "              class\n",
        "Test mode:    user supplied test set:  size unknown (reading incrementally)\n",
        "\n",
        "=== Classifier model (full training set) ===\n",
        "\n",
        "IB1 instance-based classifier\n",
        "using 1 nearest neighbour(s) for classification\n",
        "\n",
        "\n",
        "Time taken to build model: 0 seconds\n",
        "\n",
        "=== Predictions on test set ===\n",
        "\n",
        "    inst#     actual  predicted error prediction\n",
        "        1   1:setosa   1:setosa       0.974\n",
        "        2   1:setosa   1:setosa       0.974\n",
        "        3   1:setosa   1:setosa       0.974\n",
        "        4   1:setosa   1:setosa       0.974\n",
        "        5   1:setosa   1:setosa       0.974\n",
        "        6   1:setosa   1:setosa       0.974\n",
        "        7   1:setosa   1:setosa       0.974\n",
        "        8   1:setosa   1:setosa       0.974\n",
        "        9   1:setosa   1:setosa       0.974\n",
        "       10   1:setosa   1:setosa       0.974\n",
        "       11   1:setosa   1:setosa       0.974\n",
        "       12   1:setosa   1:setosa       0.974\n",
        "       13   1:setosa   1:setosa       0.974\n",
        "       14   1:setosa   1:setosa       0.974\n",
        "       15   1:setosa   1:setosa       0.974\n",
        "       16   1:setosa   1:setosa       0.974\n",
        "       17   1:setosa   1:setosa       0.974\n",
        "       18   1:setosa   1:setosa       0.974\n",
        "       19   1:setosa   1:setosa       0.974\n",
        "       20   1:setosa   1:setosa       0.974\n",
        "       21   1:setosa   1:setosa       0.974\n",
        "       22   1:setosa   1:setosa       0.974\n",
        "       23   1:setosa   1:setosa       0.974\n",
        "       24   1:setosa   1:setosa       0.974\n",
        "       25   1:setosa   1:setosa       0.974\n",
        "       26 2:versicolor 2:versicolor       0.974\n",
        "       27 2:versicolor 2:versicolor       0.974\n",
        "       28 2:versicolor 2:versicolor       0.974\n",
        "       29 2:versicolor 2:versicolor       0.974\n",
        "       30 2:versicolor 2:versicolor       0.974\n",
        "       31 2:versicolor 2:versicolor       0.974\n",
        "       32 2:versicolor 2:versicolor       0.974\n",
        "       33 2:versicolor 2:versicolor       0.974\n",
        "       34 2:versicolor 2:versicolor       0.974\n",
        "       35 2:versicolor 2:versicolor       0.974\n",
        "       36 2:versicolor 3:virginica   +   0.974\n",
        "       37 2:versicolor 3:virginica   +   0.974\n",
        "       38 2:versicolor 2:versicolor       0.974\n",
        "       39 2:versicolor 2:versicolor       0.974\n",
        "       40 2:versicolor 2:versicolor       0.974\n",
        "       41 2:versicolor 2:versicolor       0.974\n",
        "       42 2:versicolor 2:versicolor       0.974\n",
        "       43 2:versicolor 2:versicolor       0.974\n",
        "       44 2:versicolor 2:versicolor       0.974\n",
        "       45 2:versicolor 2:versicolor       0.974\n",
        "       46 2:versicolor 2:versicolor       0.974\n",
        "       47 2:versicolor 2:versicolor       0.974\n",
        "       48 2:versicolor 2:versicolor       0.974\n",
        "       49 2:versicolor 2:versicolor       0.974\n",
        "       50 2:versicolor 2:versicolor       0.974\n",
        "       51 3:virginica 3:virginica       0.974\n",
        "       52 3:virginica 3:virginica       0.974\n",
        "       53 3:virginica 3:virginica       0.974\n",
        "       54 3:virginica 3:virginica       0.974\n",
        "       55 3:virginica 3:virginica       0.974\n",
        "       56 3:virginica 3:virginica       0.974\n",
        "       57 3:virginica 3:virginica       0.974\n",
        "       58 3:virginica 3:virginica       0.974\n",
        "       59 3:virginica 3:virginica       0.974\n",
        "       60 3:virginica 2:versicolor   +   0.974\n",
        "       61 3:virginica 3:virginica       0.974\n",
        "       62 3:virginica 3:virginica       0.974\n",
        "       63 3:virginica 3:virginica       0.974\n",
        "       64 3:virginica 3:virginica       0.974\n",
        "       65 3:virginica 2:versicolor   +   0.974\n",
        "       66 3:virginica 3:virginica       0.974\n",
        "       67 3:virginica 2:versicolor   +   0.974\n",
        "       68 3:virginica 3:virginica       0.974\n",
        "       69 3:virginica 3:virginica       0.974\n",
        "       70 3:virginica 3:virginica       0.974\n",
        "       71 3:virginica 3:virginica       0.974\n",
        "       72 3:virginica 3:virginica       0.974\n",
        "       73 3:virginica 3:virginica       0.974\n",
        "       74 3:virginica 3:virginica       0.974\n",
        "       75 3:virginica 3:virginica       0.974\n",
        "\n",
        "=== Evaluation on test set ===\n",
        "\n",
        "Time taken to test model on supplied test set: 0.07 seconds\n",
        "\n",
        "=== Summary ===\n",
        "\n",
        "Correctly Classified Instances          70               93.3333 %\n",
        "Incorrectly Classified Instances         5                6.6667 %\n",
        "Kappa statistic                          0.9   \n",
        "Mean absolute error                      0.0598\n",
        "Root mean squared error                  0.2075\n",
        "Relative absolute error                 13.4615 %\n",
        "Root relative squared error             44.0212 %\n",
        "Total Number of Instances               75     \n",
        "\n",
        "=== Detailed Accuracy By Class ===\n",
        "\n",
        "                 TP Rate  FP Rate  Precision  Recall   F-Measure  MCC      ROC Area  PRC Area  Class\n",
        "                 1.000    0.000    1.000      1.000    1.000      1.000    1.000     1.000     setosa\n",
        "                 0.920    0.060    0.885      0.920    0.902      0.852    0.930     0.841     versicolor\n",
        "                 0.880    0.040    0.917      0.880    0.898      0.849    0.920     0.847     virginica\n",
        "Weighted Avg.    0.933    0.033    0.934      0.933    0.933      0.900    0.950     0.896     \n",
        "\n",
        "=== Confusion Matrix ===\n",
        "\n",
        "  a  b  c   <-- classified as\n",
        " 25  0  0 |  a = setosa\n",
        "  0 23  2 |  b = versicolor\n",
        "  0  3 22 |  c = virginica\n",
        "\n"
      ],
      "metadata": {
        "id": "Cw9FkLgiXVNV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conclusion\n",
        "\n",
        "All the 3 methods gives the same level of accuracy and answers (as expected). Therefore, everything is working fine."
      ],
      "metadata": {
        "id": "Vy31RQzRJ2JJ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_OjvA2MiHd0h"
      },
      "execution_count": 19,
      "outputs": []
    }
  ]
}